{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code to utilize trained model. A user will require an open ai key with openai api access (currently not free) and access to the pinecone.ai repository."
      ],
      "metadata": {
        "id": "Xi35sKB3GBa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install libraries required\n",
        "!pip install python-dotenv\n",
        "!pip install openai\n",
        "!pip install langchain_openai\n",
        "!pip install -U langchain-cli\n",
        "!pip install -qU pinecone-client==3.1.0 pandas==2.0.3\n",
        "!pip install langchain\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x2q-4VRBNJP",
        "outputId": "8732bed3-a88f-4d92-d8ff-50c6504730e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting openai\n",
            "  Downloading openai-1.18.0-py3-none-any.whl (292 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.18.0\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain_openai)\n",
            "  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.18.0)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading langsmith-0.1.48-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.6.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain_openai)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, tiktoken, jsonpatch, langsmith, langchain-core, langchain_openai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.42 langchain_openai-0.1.3 langsmith-0.1.48 orjson-3.10.1 packaging-23.2 tiktoken-0.6.0\n",
            "Collecting langchain-cli\n",
            "  Downloading langchain_cli-0.0.21-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython<4.0.0,>=3.1.40 (from langchain-cli)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langserve[all]>=0.0.16 (from langchain-cli)\n",
            "  Downloading langserve-0.1.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tomlkit<0.13.0,>=0.12.2 (from langchain-cli)\n",
            "  Downloading tomlkit-0.12.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cli) (0.9.4)\n",
            "Collecting uvicorn<0.24.0,>=0.23.2 (from langchain-cli)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.40->langchain-cli)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langserve[all]>=0.0.16->langchain-cli) (0.27.0)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langserve[all]>=0.0.16->langchain-cli) (0.1.42)\n",
            "Requirement already satisfied: orjson>=2 in /usr/local/lib/python3.10/dist-packages (from langserve[all]>=0.0.16->langchain-cli) (3.10.1)\n",
            "Requirement already satisfied: pydantic>=1 in /usr/local/lib/python3.10/dist-packages (from langserve[all]>=0.0.16->langchain-cli) (2.6.4)\n",
            "Collecting fastapi<1,>=0.90.1 (from langserve[all]>=0.0.16->langchain-cli)\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sse-starlette<2.0.0,>=1.3.0 (from langserve[all]>=0.0.16->langchain-cli)\n",
            "  Downloading sse_starlette-1.8.2-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (4.11.0)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<0.10.0,>=0.9.0->langchain-cli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<0.10.0,>=0.9.0->langchain-cli)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (13.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn<0.24.0,>=0.23.2->langchain-cli) (0.14.0)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.90.1->langserve[all]>=0.0.16->langchain-cli)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.40->langchain-cli)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->langserve[all]>=0.0.16->langchain-cli) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->langserve[all]>=0.0.16->langchain-cli) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->langserve[all]>=0.0.16->langchain-cli) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->langserve[all]>=0.0.16->langchain-cli) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->langserve[all]>=0.0.16->langchain-cli) (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (0.1.48)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (8.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1->langserve[all]>=0.0.16->langchain-cli) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1->langserve[all]>=0.0.16->langchain-cli) (2.16.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (2.16.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (2.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (2.31.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (0.1.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->langserve[all]>=0.0.16->langchain-cli) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.0->langserve[all]>=0.0.16->langchain-cli) (2.0.7)\n",
            "Installing collected packages: uvicorn, tomlkit, smmap, shellingham, colorama, starlette, gitdb, gitpython, fastapi, sse-starlette, langserve, langchain-cli\n",
            "Successfully installed colorama-0.4.6 fastapi-0.110.1 gitdb-4.0.11 gitpython-3.1.43 langchain-cli-0.0.21 langserve-0.1.0 shellingham-1.5.4 smmap-5.0.1 sse-starlette-1.8.2 starlette-0.37.2 tomlkit-0.12.4 uvicorn-0.23.2\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.42)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 langchain-0.1.16 langchain-community-0.0.32 langchain-text-splitters-0.0.1 marshmallow-3.21.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#library imports\n",
        "from pinecone import Pinecone\n",
        "from google.colab import userdata\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# to tokenize, chunk, and embed the text\n",
        "from openai import OpenAI\n",
        "import nltk\n",
        "import tiktoken\n",
        "from typing import List\n",
        "\n",
        "\n",
        "# to distill the results\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "\n",
        "#for user interface:\n",
        "import gradio as gr\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcyZI9NTByda",
        "outputId": "aca97201-6c24-4e44-812f-66f682de7d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGTwZWx4AeZP"
      },
      "outputs": [],
      "source": [
        "#get access to pinecone and openai\n",
        "pc = Pinecone(api_key=userdata.get('PINECONE_API_KEY'))\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "index = pc.Index('agriculture-project')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the models and essential files needed for creating chat output\n",
        "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
        "EMBED_MODEL = \"text-embedding-3-small\"\n",
        "# Store the API key in a variable.\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "MAX_TOKENS = 1536\n",
        "\n",
        "def prep(text: str):\n",
        "    return text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
        "\n",
        "def tokenize(text: List[str]):\n",
        "    encoding = tiktoken.encoding_for_model(EMBED_MODEL)\n",
        "    return encoding.encode(text)\n",
        "\n",
        "def embed(tokens: List[int]):\n",
        "    response = client.embeddings.create(input=tokens,model=EMBED_MODEL)\n",
        "    return response.data[0].embedding\n",
        "\n",
        "def chunk_text(text:str):\n",
        "    current_chunk = []\n",
        "    current_para = \"\"\n",
        "    chunks = []\n",
        "    paras = []\n",
        "    current_len = 0\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    chunks_of_tokens = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Tokenize the sentence\n",
        "        sentence_tokens = tokenize(sentence)\n",
        "        sentence_token_len = len(sentence_tokens)\n",
        "\n",
        "        # Check if adding the next sentence exceeds the max token limit\n",
        "        if current_len + sentence_token_len > MAX_TOKENS:\n",
        "            # Add the current chunk to the list and start a new one\n",
        "            paras.append(current_para)\n",
        "            current_para = \"\"\n",
        "            chunks_of_tokens.append(current_chunk)\n",
        "            embeddings = embed(current_chunk)\n",
        "            chunks.append(embeddings)\n",
        "            current_chunk = []\n",
        "            current_len = 0\n",
        "\n",
        "        # Add the sentence to the current chunk\n",
        "        current_para += \" \" + sentence\n",
        "        current_chunk.extend(sentence_tokens)\n",
        "        current_len += sentence_token_len\n",
        "\n",
        "    # Add the last chunk if it's not empty\n",
        "    if current_chunk:\n",
        "        paras.append(current_para)\n",
        "        chunks_of_tokens.append(current_chunk)\n",
        "        embeddings = embed(current_chunk)\n",
        "        chunks.append(embeddings)\n",
        "\n",
        "    return paras, chunks, chunks_of_tokens\n",
        "\n",
        "def create_embeddings(filename: str):\n",
        "    with open(filename, \"r\") as file:\n",
        "        text = file.read()\n",
        "    text = prep(text)\n",
        "    return chunk_text(text)\n",
        "\n",
        "def create_embeddings_prompt(prompt:str):\n",
        "    prompt = prep(prompt)\n",
        "    return chunk_text(prompt)\n",
        "\n",
        "def vectorize_chunks(paras: List, chunks: List, **kwargs):\n",
        "    vectors = []\n",
        "    for i in range(len(chunks)):\n",
        "        if \"filename\" in kwargs:\n",
        "            vectors.append({\"id\": f\"{i}\", \"values\": chunks[i], \"metadata\": {\"file\": filename, \"para\": f\"{paras[i]}\"}})\n",
        "        else:\n",
        "            vectors.append({\"id\": f\"{i}\", \"values\": chunks[i], \"metadata\": {\"para\": f\"{paras[i]}\"}})\n",
        "\n",
        "    return vectors"
      ],
      "metadata": {
        "id": "GcbnSgY2C4I3"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create function for taking user questions\n",
        "query_responses=[]\n",
        "\n",
        "def ask_a_question(prompt):\n",
        "    # convert the prompt to chunks of  embeddings\n",
        "    paras, chunks, chunks_of_tokens  = create_embeddings_prompt(prompt)\n",
        "    #print(f\"Embeddings: {chunks[0]}\")\n",
        "    # vectorize the embeddings\n",
        "    prompt_vectors = vectorize_chunks(paras, chunks)\n",
        "    #print(f\"Vectorized: {prompt_vectors[0]}\")\n",
        "    # search the index for the best match using semantic search\n",
        "    query_response = index.query(\n",
        "        top_k=2,\n",
        "        vector=prompt_vectors[0][\"values\"]\n",
        "    )\n",
        "    query_responses.append(query_response)\n",
        "    #print(f\"Query response: {query_response}\")\n",
        "    # get the id of the best match\n",
        "    best_id = query_response[\"matches\"][0][\"id\"]\n",
        "    #print(f\"Best ID: {best_id}\")\n",
        "    # fetch the best match from the index\n",
        "    result = index.fetch(ids=[best_id])\n",
        "    # get the paragraph of interest from the result metadata\n",
        "    para_of_interest = result[\"vectors\"][best_id][\"metadata\"][\"para\"]\n",
        "    #print(f\"Para of interest: {para_of_interest}\")\n",
        "    # Initialize the langchain chat model.\n",
        "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.0)\n",
        "    # turn the para_of_interest into a Document\n",
        "    document = Document(page_content=para_of_interest)\n",
        "    # Create the QA chain using the LLM.\n",
        "    chain = load_qa_chain(llm)\n",
        "    # Pass the para_of_interest and the prompt to the chain, and print the result.\n",
        "    #question = \"If you can't find the answer in the provided document, say, I just don't know the answer to that, otherwise, answer the question. \" + prompt\n",
        "    question = prompt\n",
        "    result = chain.invoke({\"input_documents\": [document], \"question\": question})\n",
        "    return result[\"output_text\"]"
      ],
      "metadata": {
        "id": "sPOl9aTZB5d9"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create questions to be asked\n",
        "query_responses=[]\n",
        "\n",
        "questions = [\"how many eclipses will there be this year?\",\n",
        "            \"will there be four eclipses in 2024?\",\n",
        "            \"when are the solar eclipses?\",\n",
        "            \"when are the lunar eclipses?\",\n",
        "            \"what is the date of the solar eclipse 2024?\",\n",
        "            \"what is the most popular farm animal in the United States?\",\n",
        "            \"what information do you have on duck eggs?\",\n",
        "            \"can you summarize page 201 of the almanac?\",\n",
        "            \"summarize astronomy eclipses\",\n",
        "            \"tell me what a farmer should know about farming in 2024.\"\n",
        "]\n",
        "\n",
        "answers = []\n",
        "for question in questions:\n",
        "    answers.append(ask_a_question(question))"
      ],
      "metadata": {
        "id": "p_nv4KXDCpWN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the answers\n",
        "ix = 0\n",
        "for query_response in query_responses:\n",
        "    print(f\"Match Score: {query_response['matches'][0]['score']}\")\n",
        "    print(f\"Question: {questions[ix]}\")\n",
        "    print(f\"Answer:   {answers[ix]}\\n\\n\")\n",
        "    ix += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQbBFGbuFekk",
        "outputId": "95829aad-1995-4f8f-fe67-e0e3f7fbaf0b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match Score: 0.524506092\n",
            "Question: how many eclipses will there be this year?\n",
            "Answer:   There were four lunar eclipses in 2020, all of the penumbral variety.\n",
            "\n",
            "\n",
            "Match Score: 0.488794893\n",
            "Question: will there be four eclipses in 2024?\n",
            "Answer:   I don't know.\n",
            "\n",
            "\n",
            "Match Score: 0.594897628\n",
            "Question: when are the solar eclipses?\n",
            "Answer:   Solar eclipses are rare events that occur sporadically. Any given place on Earth sees a solar totality only once every 360 years, on average. The next total solar eclipse in Los Angeles, for example, will not occur until 3290. The randomness of the universe means that relatively few people have seen a total solar eclipse.\n",
            "\n",
            "\n",
            "Match Score: 0.538452327\n",
            "Question: when are the lunar eclipses?\n",
            "Answer:   There will be a penumbral lunar eclipse on March 24-25, 2024.\n",
            "\n",
            "\n",
            "Match Score: 0.550877869\n",
            "Question: what is the date of the solar eclipse 2024?\n",
            "Answer:   The total solar eclipse of 2024 will occur on April 8th.\n",
            "\n",
            "\n",
            "Match Score: 0.43765232\n",
            "Question: what is the most popular farm animal in the United States?\n",
            "Answer:   I don't have information on the most popular farm animal in the United States based on the provided context.\n",
            "\n",
            "\n",
            "Match Score: 0.299920082\n",
            "Question: what information do you have on duck eggs?\n",
            "Answer:   I don't have specific information on duck eggs based on the context provided.\n",
            "\n",
            "\n",
            "Match Score: 0.59830004\n",
            "Question: can you summarize page 201 of the almanac?\n",
            "Answer:   I'm sorry, but based on the context provided, there is no information about the content of page 201 of the Almanac.\n",
            "\n",
            "\n",
            "Match Score: 0.563002765\n",
            "Question: summarize astronomy eclipses\n",
            "Answer:   Astronomy eclipses, both solar and lunar, are rare and brief events that offer different experiences for observers. Solar eclipses occur when the Moon blocks the Sun's light, with totality lasting just a few minutes and happening in any given place on Earth once every 360 years on average. Lunar eclipses, on the other hand, occur when the Moon enters Earth's shadow, but the type of shadow (umbra or penumbra) affects the experience for viewers. It's important to understand the differences between these types of eclipses to fully appreciate and enjoy them.\n",
            "\n",
            "\n",
            "Match Score: 0.526264548\n",
            "Question: tell me what a farmer should know about farming in 2024.\n",
            "Answer:   A farmer in 2024 should be aware of the following key points based on the provided context:\n",
            "\n",
            "1. Labor shortages are a significant challenge in farming, so farmers should be prepared to address this issue by finding innovative solutions or technologies to maintain operations.\n",
            "2. Establishing strong customer connections and becoming an employer of choice is crucial for attracting and retaining the best employees.\n",
            "3. On-farm shops that invite local producers to sell their products can help farmers diversify their offerings and attract more customers.\n",
            "4. Vertical farming near urban centers, raising fish, and controlled indoor plant production are emerging trends that farmers should consider to adapt to changing agricultural landscapes.\n",
            "5. Factors such as high input costs, interest rates, diseases affecting animals or plants, and ongoing labor shortages are key challenges that farmers should be prepared to navigate in 2024.\n",
            "\n",
            "These points highlight the importance of innovation, adaptability, and strategic planning for farmers in 2024.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_input = gr.Textbox(label=\"Ask a Question to the Farmer's Almanac\")\n",
        "iface = gr.Interface(\n",
        "    fn=ask_a_question,\n",
        "    inputs=question_input,\n",
        "    outputs=\"text\",  # We expect a text output\n",
        "    title=\"Question Answering GUI\",\n",
        "    description=\"Ask a question and get an answer.\",\n",
        ")\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "npVMyRI-NvDS",
        "outputId": "6bebd7e2-8d7e-4c6c-9760-72dd2dfe2229"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://6735a76cb97eccdf37.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6735a76cb97eccdf37.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ]
}